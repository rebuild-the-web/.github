# Rebuild the web

## Why?

### The scope of the web platform is too big

[Drew Devault pointed out in 2020](https://drewdevault.com/2020/03/18/Reckless-limitless-scope.html) that the web platforms specification is just too large, making implementing it anew securely and reliably a near-impossible and extremely expensive task.

The achievment of the [Ladybird browser](https://ladybird.org/) demonstrated that the task is not quite impossible yet, but the competition on new browsers is certainly not as lively as it could be.

### Creating good-looking, responsive, secure, performant and accessible websites and webapps is still not easy

The classic declarative way of HTML+CSS makes it easy to create a static webiste that just works.

But the expectations are a lot higher in 2025, leading most webapps to be built with complicated javascript frameworks. For many people the default way is quickly becoming to prompt an LLM.

A lot of websites, even that of big companies and reputable organizations are broken one way or another, or offer a less-than-good user experience.

In the past, it was possible to 'View Source' a page, and learn something from it. [Not anymore](https://htmx.org/essays/right-click-view-source/).

### AI-generated slop content is endangering the open web

Low-quality content farms are nothing new, but AI certainly makes things even worse. The declining usefulness of Google Search results was noticed and bemoaned by many in the last years.

### AI training piracy is undermining the incentives that once led people to publish quality information publicly

Why add value to the commons, if AI will steal it without attribution? Even if one doesn't mind, feckless data scraping for AI training purposes creates [real pain on maintainers](https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html).

## How?

No one has all the answers. But we can still figure it out.

